# Memory-Optimized TTT-Only Training Configuration (No Paper Metrics)
# Designed to fit on single 48GB GPU with TTT-only training

# Data configuration
data:
  train_data: /sise/eliyanac-group/ron_al/daily-talk-contiguous/train/dailytalk_train.jsonl
  eval_data: /sise/eliyanac-group/ron_al/daily-talk-contiguous/eval/dailytalk_eval.jsonl
  shuffle: true

# Training run configuration
run_dir: runs/production_ttt_only_moshi_dailytalk_no_metrics
overwrite_run_dir: true

# Model paths
moshi_paths:
  hf_repo_id: kyutai/moshiko-pytorch-bf16
  moshi_path: null
  mimi_path: null
  tokenizer_path: null
  config_path: null

# LoRA configuration (DISABLED - only training TTT)
lora:
  enable: false         # Disable LoRA - only train TTT parameters
  rank: 32              
  scaling: 2.0
  ft_embed: false

# TTT (Test-Time Training) configuration
ttt:
  enable: true
  layers: "middle"      # Apply TTT to middle layers only
  base_lr: 1.0         
  mini_batch_size: 16   # Larger mini-batch for fewer sequential steps

# Training parameters
full_finetuning: false  # Freeze base model, only train TTT
duration_sec: 10.0      # Shorter sequences for faster training
batch_size: 2           # Can use larger batch since only training TTT
num_microbatches: 4     # Gradient accumulation for effective batch size of 8
max_steps: 1000         # Production training run
log_freq: 10            # Log every 10 steps

# Loss weighting
first_codebook_weight_multiplier: 2.0
text_padding_weight: 0.5

# Optimizer configuration  
optim:
  lr: 3e-5              # Lower learning rate for stable TTT training
  weight_decay: 0.1
  pct_start: 0.05

# Regularization
max_norm: 1.0           # Gradient clipping for TTT stability

# Checkpointing
do_ckpt: true
ckpt_freq: 100          # Checkpoint every 100 steps
save_adapters: true     # Save LoRA adapters only for efficiency
num_ckpt_keep: 5

# Evaluation (basic only)
do_eval: true
eval_freq: 200          # Less frequent evaluation to save time

# Paper metrics evaluation (DISABLED to avoid missing file issues)
paper_metrics:
  paper_metrics_eval: false  # Disable problematic paper metrics

# System configuration
seed: 42
gradient_checkpointing: true  # Essential for memory efficiency
param_dtype: bfloat16         # Mixed precision for efficiency

# Monitoring
wandb:
  project: ttt-moshi-production
  offline: false
  run_name: production_ttt_only_moshi_dailytalk_no_metrics
