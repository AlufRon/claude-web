#!/usr/bin/env bash
#SBATCH --partition=main                  # use main partition
#SBATCH --job-name=moshi_inference        # job name
#SBATCH --output=/home/alufr/ttt_tests/moshi-finetune/logs/inference/moshi_inference.%j.log   # STDOUT ‚Üí logs/inference/moshi_inference.<JOBID>.log
#SBATCH --error=/home/alufr/ttt_tests/moshi-finetune/logs/inference/moshi_inference.%j.err    # STDERR ‚Üí logs/inference/moshi_inference.<JOBID>.err
#SBATCH --ntasks=1                        # one task/process
#SBATCH --cpus-per-task=4                 # CPU cores
#SBATCH --gpus=1                          # 1 GPU
#SBATCH --constraint=rtx_6000             # prefer RTX 6000
#SBATCH --mem=50G                         # host RAM
#SBATCH --time=24:00:00                    # walltime hh:mm:ss (2 hours)
#SBATCH --exclude=cs-6000-01,cs-6000-02,cs-6000-03,cs-6000-04,ise-6000-08,ise-6000-07   # exclude problematic nodes

# Pin to the first (and only) visible GPU
export CUDA_VISIBLE_DEVICES=0

# Fix CUDA memory fragmentation
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# Load & activate conda environment
module load anaconda
eval "$(conda shell.bash hook)"
conda activate moshi_ttt_fixed

# Force proper environment activation
export PATH="$CONDA_PREFIX/bin:$PATH"
export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:$LD_LIBRARY_PATH"

# Verify environment
echo "üêç Active conda environment: $CONDA_DEFAULT_ENV"
echo "üêç Python path: $(which python)"
echo "üêç Python version: $(python --version)"

# GPU Diagnostics
echo "üîß GPU Diagnostics:"
echo "üîß Hostname: $(hostname)"
echo "üîß SLURM_JOB_ID: $SLURM_JOB_ID"
echo "üîß CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"

# Test nvidia-smi
if command -v nvidia-smi &> /dev/null; then
    echo "üîß nvidia-smi output:"
    nvidia-smi || echo "‚ùå nvidia-smi failed"
else
    echo "‚ùå nvidia-smi not found"
fi

# Get parameters from environment variables (set by submit script)
CHECKPOINT_DIR=${CHECKPOINT_DIR}
INPUT_AUDIO=${INPUT_AUDIO}
OUTPUT_AUDIO=${OUTPUT_AUDIO}
HF_REPO=${HF_REPO:-kyutai/moshiko-pytorch-bf16}
REPETITION_PENALTY=${REPETITION_PENALTY:-1.0}
REPETITION_WINDOW=${REPETITION_WINDOW:-64}

# Change to moshi-finetune directory
cd /home/alufr/ttt_tests/moshi-finetune

# Add current directory to PYTHONPATH for module imports
export PYTHONPATH="/home/alufr/ttt_tests/moshi-finetune:$PYTHONPATH"

echo "üöÄ Starting Moshi TTT Inference"
echo "=============================="
echo "üìÅ Checkpoint: $CHECKPOINT_DIR"
echo "üé§ Input audio: $INPUT_AUDIO"
echo "üîä Output audio: $OUTPUT_AUDIO"
echo "ü§ó HF repo: $HF_REPO"
echo "üîÑ Repetition penalty: $REPETITION_PENALTY"
echo "üìè Repetition window: $REPETITION_WINDOW"
echo ""

# Verify checkpoint exists
if [ ! -d "$CHECKPOINT_DIR" ]; then
    echo "‚ùå Error: Checkpoint directory '$CHECKPOINT_DIR' not found!"
    exit 1
fi

# Verify input audio exists
if [ ! -f "$INPUT_AUDIO" ]; then
    echo "‚ùå Error: Input audio file '$INPUT_AUDIO' not found!"
    exit 1
fi

# Run inference
echo "üèÉ Starting TTT inference..."
python inference/run_inference_with_ttt.py \
    --checkpoint "$CHECKPOINT_DIR" \
    --hf-repo "$HF_REPO" \
    --repetition-penalty "$REPETITION_PENALTY" \
    --repetition-window "$REPETITION_WINDOW" \
    "$INPUT_AUDIO" \
    "$OUTPUT_AUDIO"

EXIT_CODE=$?

if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo "‚úÖ Inference completed successfully!"
    echo "üîä Output saved to: $OUTPUT_AUDIO"
else
    echo ""
    echo "‚ùå Inference failed with exit code $EXIT_CODE"
    exit $EXIT_CODE
fi
