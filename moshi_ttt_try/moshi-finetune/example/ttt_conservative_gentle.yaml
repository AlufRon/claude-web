# TTT CONSERVATIVE GENTLE - Preserve Linguistic Knowledge
# base_lr: 0.0001 (gentle TTT adaptation to avoid catastrophic forgetting)
# data
data:
  train_data: /sise/eliyanac-group/ron_al/seamless_interaction/daily_format_output/dailytalk.jsonl
  eval_data: /sise/eliyanac-group/ron_al/seamless_interaction/daily_format_output/dailytalk.jsonl
  shuffle: false

# RoPE Configuration (applies to ALL Moshi transformer layers)
rope_continuous: true  # Enable continuous RoPE positions across chunks from same file
rope_reset_on_new_file: true  # Reset positions when new file begins

ttt:
  enable: true  # TTT ENABLED with gentle adaptation
  layers: "29,30,31"  # Final 3 layers
  base_lr: 0.0001   # GENTLE TTT learning rate (100x smaller than aggressive)
  mini_batch_size: 16  # Standard mini-batch size
  persistent_states: true  # Enable TTT state persistence

# model
moshi_paths: 
  hf_repo_id: "kyutai/moshiko-pytorch-bf16"

full_finetuning: false 
lora:
  enable: true 
  rank: 64
  scaling: 2.
  ft_embed: false 

paper_metrics:
  paper_metrics_eval: true
  paper_metrics_freq: 10  # Evaluate every 10 steps
  paper_metrics_use_silence: true
  paper_metrics_use_user_stream: false
  sblimp_audio_dir: /sise/eliyanac-group/ron_al/sblimp_data/sLM21_dataset/syntactic/test/
  sblimp_gold_csv: /sise/eliyanac-group/ron_al/sblimp_data/sLM21_dataset/syntactic/test/gold.csv
  sblimp_max_pairs: 10
  sstory_audio_dir: /sise/eliyanac-group/ron_al/sSC/sSC/
  sstory_max_pairs: 10
  swuggy_audio_dir: /sise/eliyanac-group/ron_al/sblimp_data/sLM21_dataset/lexical/test/
  swuggy_gold_csv: /sise/eliyanac-group/ron_al/sblimp_data/sLM21_dataset/syntactic/test/gold.csv
  swuggy_max_pairs: 10
  tstory_audio_dir: /sise/eliyanac-group/ron_al/tSC/tSC/
  tstory_max_pairs: 10
  # LibriLight Long Context Evaluation (TTT Paper methodology)
  librilight_audio_dir: /sise/eliyanac-group/ron_al/librilight/extracted_medium/medium/
  librilight_evaluation_mode: single_book
  librilight_speaker_id: "100"
  librilight_book_name: "emerald_city_librivox_64kb_mp3"
  librilight_max_chapters: 3
  librilight_num_sequences: 1

first_codebook_weight_multiplier: 100.
text_padding_weight: .5

# optim - same as baseline for fair comparison
duration_sec: 300  # 5 minutes (same as baseline)
batch_size: 1      # Same batch size
max_steps: 2000    # Same number of steps
gradient_checkpointing: true
optim:
  lr: 1e-6         # SAME main learning rate as baseline
  weight_decay: 0.1
  pct_start: 0.05

# other
seed: 42  # Different seed for independent comparison
log_freq: 10
eval_freq: 50  # Same eval frequency
do_eval: true
do_ckpt: true
ckpt_freq: 50

save_adapters: true

run_dir: /sise/eliyanac-group/ron_al/ttt_conservative_gentle

wandb:
  project: ttt-moshi-long-conversations
  offline: false
  run_name: ttt_conservative_gentle_preserve_linguistic