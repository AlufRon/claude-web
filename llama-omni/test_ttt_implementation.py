"""
Test TTT Implementation

This script tests the TTT implementation step-by-step:
1. Configuration validation
2. Model creation with and without TTT
3. Forward pass
4. State persistence
5. CSV logging
6. Integration verification

Run with:
    python test_ttt_implementation.py
"""

import torch
import logging
from pathlib import Path
import sys

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def test_config_validation():
    """Test 1: Configuration validation."""
    logger.info("=" * 80)
    logger.info("Test 1: Configuration Validation")
    logger.info("=" * 80)

    from omni_speech.model.language_model.omni_speech_llama import OmniSpeechConfig

    # Test 1.1: TTT disabled (should work)
    logger.info("Test 1.1: TTT disabled")
    config_no_ttt = OmniSpeechConfig(use_ttt=False)
    assert config_no_ttt.use_ttt == False
    logger.info("‚úì TTT disabled config works")

    # Test 1.2: TTT enabled with valid params
    logger.info("Test 1.2: TTT enabled with valid params")
    config_with_ttt = OmniSpeechConfig(
        use_ttt=True,
        ttt_layer_type="ttt_linear",
        ttt_mini_batch_size=64,
        ttt_base_lr=1.0,
        ttt_state_dtype="float32",
    )
    assert config_with_ttt.use_ttt == True
    assert config_with_ttt.ttt_state_dtype == "float32"
    logger.info("‚úì TTT enabled config works")

    # Test 1.3: Invalid state dtype (should fail)
    logger.info("Test 1.3: Invalid state dtype (should fail)")
    try:
        bad_config = OmniSpeechConfig(
            use_ttt=True,
            ttt_state_dtype="float16",  # Should fail!
        )
        logger.error("‚úó Should have raised assertion error!")
        return False
    except AssertionError as e:
        logger.info(f"‚úì Correctly raised error: {str(e)[:100]}")

    # Test 1.4: Invalid mini_batch_size (should fail)
    logger.info("Test 1.4: Invalid mini_batch_size (should fail)")
    try:
        bad_config = OmniSpeechConfig(
            use_ttt=True,
            ttt_mini_batch_size=200,  # Too large!
        )
        logger.error("‚úó Should have raised assertion error!")
        return False
    except AssertionError:
        logger.info("‚úì Correctly raised error for invalid mini_batch_size")

    logger.info("=" * 80)
    logger.info("Test 1: PASSED ‚úì")
    logger.info("=" * 80)
    return True


def test_model_creation():
    """Test 2: Model creation with and without TTT."""
    logger.info("=" * 80)
    logger.info("Test 2: Model Creation")
    logger.info("=" * 80)

    from omni_speech.model.language_model.omni_speech_llama import (
        OmniSpeechConfig,
        OmniSpeechLlamaForCausalLM
    )
    from omni_speech.model.ttt.ttt_layer import TTTLinearLayer

    # Test 2.1: Model without TTT
    logger.info("Test 2.1: Creating model WITHOUT TTT")
    config_no_ttt = OmniSpeechConfig(
        use_ttt=False,
        hidden_size=256,  # Small for testing
        num_hidden_layers=4,
        num_attention_heads=4,
        intermediate_size=1024,
    )

    model_no_ttt = OmniSpeechLlamaForCausalLM(config_no_ttt)

    # Check layers use standard attention
    from transformers.models.llama.modeling_llama import LlamaAttention, LlamaSdpaAttention, LlamaFlashAttention2
    attention_types = (LlamaAttention, LlamaSdpaAttention, LlamaFlashAttention2)

    for layer_idx, layer in enumerate(model_no_ttt.model.layers):
        if not isinstance(layer.self_attn, attention_types):
            logger.error(f"‚úó Layer {layer_idx} should use standard attention, got {type(layer.self_attn)}")
            return False

    logger.info("‚úì Model without TTT uses standard attention")

    # Test 2.2: Model with TTT (minimal config for testing)
    logger.info("Test 2.2: Creating model WITH TTT")
    config_with_ttt = OmniSpeechConfig(
        use_ttt=True,
        ttt_layer_type="ttt_linear",
        ttt_mini_batch_size=16,  # Small for testing
        ttt_layer_indices=[2, 3],  # Only top 2 layers
        hidden_size=256,
        num_hidden_layers=4,
        num_attention_heads=4,
        intermediate_size=1024,
        ttt_enable_logging=True,
        ttt_log_level="INFO",
    )

    model_with_ttt = OmniSpeechLlamaForCausalLM(config_with_ttt)

    # Check correct layers use TTT
    for layer_idx, layer in enumerate(model_with_ttt.model.layers):
        if layer_idx in [2, 3]:
            if not isinstance(layer.self_attn, TTTLinearLayer):
                logger.error(f"‚úó Layer {layer_idx} should use TTT, got {type(layer.self_attn)}")
                return False
        else:
            if isinstance(layer.self_attn, TTTLinearLayer):
                logger.error(f"‚úó Layer {layer_idx} should use standard attention, got {type(layer.self_attn)}")
                return False

    logger.info("‚úì Model with TTT uses TTT in specified layers")

    # Test 2.3: Verify W1, b1 are float32
    logger.info("Test 2.3: Verifying W1, b1 are float32")
    for layer_idx in [2, 3]:
        W1 = model_with_ttt.model.layers[layer_idx].self_attn.W1
        b1 = model_with_ttt.model.layers[layer_idx].self_attn.b1

        if W1.dtype != torch.float32:
            logger.error(f"‚úó Layer {layer_idx} W1 is {W1.dtype}, expected torch.float32")
            return False
        if b1.dtype != torch.float32:
            logger.error(f"‚úó Layer {layer_idx} b1 is {b1.dtype}, expected torch.float32")
            return False

    logger.info("‚úì All TTT states are float32")

    logger.info("=" * 80)
    logger.info("Test 2: PASSED ‚úì")
    logger.info("=" * 80)
    return True


def test_forward_pass():
    """Test 3: Forward pass with TTT."""
    logger.info("=" * 80)
    logger.info("Test 3: Forward Pass")
    logger.info("=" * 80)

    from omni_speech.model.language_model.omni_speech_llama import (
        OmniSpeechConfig,
        OmniSpeechLlamaForCausalLM
    )

    # Create model
    config = OmniSpeechConfig(
        use_ttt=True,
        ttt_layer_type="ttt_linear",
        ttt_mini_batch_size=16,
        ttt_layer_indices=[2, 3],
        hidden_size=256,
        num_hidden_layers=4,
        num_attention_heads=4,
        intermediate_size=1024,
        vocab_size=1000,
        ttt_enable_logging=False,  # Disable for test
    )

    model = OmniSpeechLlamaForCausalLM(config)
    model.eval()

    # Test 3.1: Forward pass with valid sequence length
    logger.info("Test 3.1: Forward pass with sequence length divisible by mini_batch_size")
    batch_size = 2
    seq_len = 32  # Divisible by mini_batch_size=16

    input_ids = torch.randint(0, 1000, (batch_size, seq_len))

    try:
        with torch.no_grad():
            outputs = model(input_ids=input_ids)

        assert outputs.logits.shape == (batch_size, seq_len, 1000)
        logger.info(f"‚úì Forward pass successful, output shape: {outputs.logits.shape}")
    except Exception as e:
        logger.error(f"‚úó Forward pass failed: {e}")
        return False

    # Test 3.2: Forward pass with invalid sequence length (should fail or auto-pad)
    logger.info("Test 3.2: Forward pass with sequence length NOT divisible by mini_batch_size")
    seq_len_invalid = 30  # NOT divisible by 16

    input_ids_invalid = torch.randint(0, 1000, (batch_size, seq_len_invalid))

    try:
        with torch.no_grad():
            outputs = model(input_ids=input_ids_invalid)
        logger.error("‚úó Should have raised an error for invalid sequence length!")
        # NOTE: If you implement auto-padding, this test should pass
        # For now, we expect it to fail
    except ValueError as e:
        logger.info(f"‚úì Correctly raised error: {str(e)[:100]}")

    logger.info("=" * 80)
    logger.info("Test 3: PASSED ‚úì")
    logger.info("=" * 80)
    return True


def test_csv_logging():
    """Test 4: CSV logging."""
    logger.info("=" * 80)
    logger.info("Test 4: CSV Logging")
    logger.info("=" * 80)

    from omni_speech.model.ttt.logger import TTTCSVLogger
    import tempfile
    import pandas as pd

    # Create temporary log file
    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
        log_path = f.name

    logger.info(f"Test 4.1: Creating CSV logger at {log_path}")
    csv_logger = TTTCSVLogger(log_path=log_path, flush_interval=5)

    # Log some states
    logger.info("Test 4.2: Logging states")
    W1_test = torch.randn(4, 64, 64)
    b1_test = torch.randn(4, 1, 64)

    for step in range(10):
        csv_logger.log_state(
            layer_idx=0,
            step=step,
            conversation_id="test_conv",
            W1=W1_test,
            b1=b1_test,
            grad_norm=0.1 * step,
            loss=0.5 / (step + 1),
        )

    # Flush to disk
    csv_logger.flush()

    # Read and validate
    logger.info("Test 4.3: Reading and validating CSV")
    df = pd.read_csv(log_path)

    assert len(df) == 10, f"Expected 10 rows, got {len(df)}"
    assert 'w1_mean' in df.columns
    assert 'b1_std' in df.columns
    assert 'grad_norm' in df.columns

    logger.info(f"‚úì CSV contains {len(df)} rows with correct columns")
    logger.info(f"  Columns: {list(df.columns)[:5]}...")

    # Cleanup
    Path(log_path).unlink()

    logger.info("=" * 80)
    logger.info("Test 4: PASSED ‚úì")
    logger.info("=" * 80)
    return True


def main():
    """Run all tests."""
    logger.info("\n" + "=" * 80)
    logger.info("TTT IMPLEMENTATION TEST SUITE")
    logger.info("=" * 80 + "\n")

    tests = [
        ("Configuration Validation", test_config_validation),
        ("Model Creation", test_model_creation),
        ("Forward Pass", test_forward_pass),
        ("CSV Logging", test_csv_logging),
    ]

    results = {}

    for test_name, test_func in tests:
        try:
            logger.info(f"\nRunning: {test_name}")
            success = test_func()
            results[test_name] = success
        except Exception as e:
            logger.error(f"\n‚úó {test_name} FAILED with exception:")
            logger.error(f"  {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            results[test_name] = False

    # Summary
    logger.info("\n" + "=" * 80)
    logger.info("TEST SUMMARY")
    logger.info("=" * 80)

    total = len(results)
    passed = sum(results.values())

    for test_name, success in results.items():
        status = "‚úì PASSED" if success else "‚úó FAILED"
        logger.info(f"  {test_name}: {status}")

    logger.info("=" * 80)
    logger.info(f"Total: {passed}/{total} tests passed")
    logger.info("=" * 80)

    if passed == total:
        logger.info("\nüéâ ALL TESTS PASSED! TTT implementation is ready.")
        return 0
    else:
        logger.error(f"\n‚ùå {total - passed} tests failed. Please review errors above.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
